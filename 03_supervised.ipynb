{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvUoarXA0IFCh8vtevgLNO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wakristensen/machine-learning-workshop/blob/main/03_supervised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Salgsprediksjon med regresjon og XGBoost\n",
        "\n",
        "Vi skal:\n",
        "\n",
        "1) Hente og preppe salgsdata\n",
        "\n",
        "2) Lage et tidsserie-sett\n",
        "\n",
        "3) Trene en regresjonsmodell og en XGBoost model\n",
        "\n",
        "4) Evualere modellene\n",
        "\n",
        "5) Gjøre fremtidige prediksjoner"
      ],
      "metadata": {
        "id": "y-yJjp0YCuaH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importerer biblioteker"
      ],
      "metadata": {
        "id": "-aLWQ4N9DOQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "from xgboost.callback import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "ceeESQfbDMnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importerer datasettet"
      ],
      "metadata": {
        "id": "tlxjCQdUDTf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = \"1Ku-y5BE5CdGQwzEMQ491cfIYWILS6T8U\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "df = pd.read_csv(url, encoding=\"latin1\")"
      ],
      "metadata": {
        "id": "XEOOtra8DVaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preppe data for tidsserie-prediksjoner"
      ],
      "metadata": {
        "id": "aFQQ7eBCDgBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Produktfokusert datasett for antall salg ---\n",
        "\n",
        "# Sikre riktig dtype\n",
        "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
        "\n",
        "# Fjerner kansellerte og negative linjer, slik at \"antall salg\" kun betyr positive salg\n",
        "# Kansellerte transaksjoner har InvoiceNo som starter med 'C', negativ Quantity, og samme UnitPrice som originalen\n",
        "df_prod = df.copy()\n",
        "\n",
        "# Finne kansellerte transaksjoner\n",
        "cancelled_transactions = df_prod[df_prod['InvoiceNo'].astype(str).str.startswith('C')].copy()\n",
        "\n",
        "# Lager en unik nøkkel for å matche kansellerte transaksjoner med originale counterparts\n",
        "cancelled_transactions['match_key'] = cancelled_transactions['StockCode'].astype(str) + '_' + \\\n",
        "                                      cancelled_transactions['CustomerID'].astype(str) + '_' + \\\n",
        "                                      (cancelled_transactions['Quantity'] * -1).astype(str) + '_' + \\\n",
        "                                      cancelled_transactions['UnitPrice'].astype(str)\n",
        "\n",
        "# Finner originale transaksjoner som matcher de kansellerte\n",
        "df_prod['match_key'] = df_prod['StockCode'].astype(str) + '_' + \\\n",
        "                       df_prod['CustomerID'].astype(str) + '_' + \\\n",
        "                       df_prod['Quantity'].astype(str) + '_' + \\\n",
        "                       df_prod['UnitPrice'].astype(str)\n",
        "\n",
        "# Finner transaksjoner vi skal fjerne (kansellerte transaksjoner og deres positive counterparts)\n",
        "keys_to_remove = cancelled_transactions['match_key'].tolist()\n",
        "\n",
        "# Filtrerer vekk transaksjoner vi skal fjerne\n",
        "df_prod = df_prod[~df_prod['match_key'].isin(keys_to_remove)].copy()\n",
        "\n",
        "# Fjerner den midlertidig match-nøkkelen\n",
        "df_prod = df_prod.drop(columns=['match_key'])\n",
        "\n",
        "# Sikrer at utelukkende positive kvantiteter og unit priser står igje\n",
        "df_prod = df_prod[(df_prod['Quantity'] > 0) & (df_prod['UnitPrice'] > 0)]\n",
        "\n",
        "\n",
        "# Topp 10 etter frekvens av Description\n",
        "top_products = df_prod['Description'].value_counts().head(10)\n",
        "print(\"Topp 10 produkter:\", top_products)\n",
        "\n",
        "# Velg mest frekvente beskrivelse\n",
        "TOP_PRODUCT = df_prod['Description'].value_counts().reset_index().iloc[2][0]\n",
        "print(\"Produkt valgt (Description):\", TOP_PRODUCT)\n",
        "\n",
        "# Filtrer på Description, ikke StockCode\n",
        "prod_df = df_prod[df_prod['Description'] == TOP_PRODUCT].copy()\n",
        "\n",
        "# Sikre datetime og lag eksplisitt Date-kolonne\n",
        "prod_df['InvoiceDate'] = pd.to_datetime(prod_df['InvoiceDate'], errors='coerce')\n",
        "prod_df = prod_df.dropna(subset=['InvoiceDate'])\n",
        "\n",
        "# Behold dtype datetime64 ved å normalisere til midnatt (bedre for plotting og sortering)\n",
        "prod_df['Date'] = prod_df['InvoiceDate'].dt.normalize()\n",
        "\n",
        "# Gruppér per dag og summer Quantity\n",
        "daily_prod_sales = (\n",
        "    prod_df\n",
        "    .groupby('Date', as_index=False)['Quantity']\n",
        "    .sum()\n",
        "    .rename(columns={'Quantity': 'SalesCount'})\n",
        "    .sort_values('Date')\n",
        ")\n",
        "\n",
        "print(\"Form på daglig datasett:\", daily_prod_sales.shape)\n",
        "daily_prod_sales"
      ],
      "metadata": {
        "id": "b6IkIJe4DjKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_prod[df_prod.Description == \"REGENCY CAKESTAND 3 TIER\"].StockCode.value_counts()"
      ],
      "metadata": {
        "id": "7jZMO1iMN0Xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_prod[df_prod.StockCode == \"22423\"].sort_values('Quantity', ascending=False).head(10)"
      ],
      "metadata": {
        "id": "H4Bn-XWHRrHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "enDDa83OE7fh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Blokk 4: EDA for det mest solgte produktet ---\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Plot daglig antall salg for toppproduktet\n",
        "plt.figure(figsize=(12, 5))\n",
        "sns.lineplot(x='Date', y='SalesCount', data=daily_prod_sales)\n",
        "plt.title(f'Daglig antall salg – Produkt {TOP_PRODUCT}')\n",
        "plt.xlabel('Dato')\n",
        "plt.ylabel('Antall solgte enheter')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Fordeling av daglig antall salg\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.histplot(daily_prod_sales['SalesCount'], bins=20, kde=True)\n",
        "plt.title('Fordeling av daglig salg – salg per dag')\n",
        "plt.xlabel('Antall salg')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Rullerende gjennomsnitt (7 dager)\n",
        "daily_prod_sales['Rolling7'] = daily_prod_sales['SalesCount'].rolling(window=7).mean()\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "sns.lineplot(x='Date', y='SalesCount', label='Faktisk', data=daily_prod_sales)\n",
        "sns.lineplot(x='Date', y='Rolling7', label='7-dagers rullerende snitt', data=daily_prod_sales, color='orange')\n",
        "plt.title('Daglig salg med 7-dagers rullende snitt')\n",
        "plt.xlabel('Dato')\n",
        "plt.ylabel('Antall salg')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lVi9YzMmFBXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Features for antall salg  ---\n",
        "\n",
        "def make_prod_features(df):\n",
        "    df = df.copy()\n",
        "    # Lag enkle tidsvariabler\n",
        "    df['year'] = df['Date'].dt.year\n",
        "    df['month'] = df['Date'].dt.month\n",
        "    df['dayofweek'] = df['Date'].dt.dayofweek  # 0 = mandag\n",
        "\n",
        "    # Enkle lag og rullerende gjennomsnitt\n",
        "    df['lag_1'] = df['SalesCount'].shift(1)\n",
        "    df['lag_7'] = df['SalesCount'].shift(7)\n",
        "    df['roll_mean_7'] = df['SalesCount'].rolling(7).mean()\n",
        "\n",
        "    # Dropp NaN som kommer fra lag/rolling\n",
        "    df = df.dropna()\n",
        "\n",
        "    feature_cols = ['year', 'month', 'dayofweek', 'lag_1', 'lag_7', 'roll_mean_7']\n",
        "    X = df[feature_cols]\n",
        "    y = df['SalesCount']\n",
        "    return df, X, y, feature_cols\n",
        "\n",
        "features_df, X, y, feature_cols = make_prod_features(daily_prod_sales)\n",
        "features_df\n"
      ],
      "metadata": {
        "id": "JO8ydWLKFmH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "b_h42xicystJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Trener to modeller og sammenligner ---\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score\n",
        "\n",
        "# Tidsserie-splitt: ikke shuffle\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, shuffle=False\n",
        ")\n",
        "\n",
        "# 1) Lineær regresjon\n",
        "linreg = LinearRegression()\n",
        "linreg.fit(X_train, y_train)\n",
        "y_pred_lin = linreg.predict(X_test)\n",
        "\n",
        "# 2) XGBoost-regresjon\n",
        "xgb = XGBRegressor(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=4,\n",
        "    random_state=42,\n",
        "    eval_metric='rmse',\n",
        "    early_stopping_rounds=30\n",
        ")\n",
        "xgb.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "\n",
        "# Evaluer\n",
        "def report(y_true, y_pred, name):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = root_mean_squared_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    print(f\"{name} -> MAE: {mae:.2f} | RMSE: {rmse:.2f} | R²: {r2:.3f}\")\n",
        "\n",
        "print(\"Modellkvalitet på hold-out:\")\n",
        "report(y_test, y_pred_lin, \"LinearRegression\")\n",
        "report(y_test, y_pred_xgb, \"XGBRegressor\")\n"
      ],
      "metadata": {
        "id": "Vh5JXKJlGV0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MEA - Mean absolute error: Gjennomsnittlig absolutt feil i samme enhet som målvariabel, intuitiv å forstå\n",
        "\n",
        "RMSE - Root mean squared error: Straffer store feil sterkere, følsom for outliers.\n",
        "\n",
        "R² - bestemmelseskoeffisient (\n",
        "  - 0\tThe model does not predict the outcome.\n",
        "  - Between 0 and 1\tThe model partially predicts the outcome.\n",
        "  - 1\tThe model perfectly predicts the outcome.)\n",
        "\n",
        "R² sier noe om hvor mye av variasjonen modellen klarer å forklare med de parameterne den har."
      ],
      "metadata": {
        "id": "4BOYySEKVkk_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modell-evaluering"
      ],
      "metadata": {
        "id": "I77I5SCpHx2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Visualisering og feature-viktighet: LinearRegression ---\n",
        "\n",
        "# 1) Predikert vs. faktisk for LinearRegression\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(y_test, y_pred_lin, alpha=0.5)\n",
        "lims = [min(y_test.min(), y_pred_lin.min()), max(y_test.max(), y_pred_lin.max())]\n",
        "plt.plot(lims, lims, 'r--')\n",
        "plt.xlabel('Faktisk antall salg')\n",
        "plt.ylabel('Predikert antall salg')\n",
        "plt.title(f'Faktisk vs. predikert, produkt {TOP_PRODUCT} (LinearRegression)')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 2) Feature-viktighet for LinearRegression\n",
        "# Merk: koeffisienter er skalaavhengige. For å sammenligne rettferdig,\n",
        "# standardiserer vi X_kolonner fra treningssettet og skalerer koeffisientene tilsvarende.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Bygg en scaler på treningsdata\n",
        "scaler_lr = StandardScaler(with_mean=True, with_std=True)\n",
        "X_train_scaled = scaler_lr.fit_transform(X_train)\n",
        "X_test_scaled = scaler_lr.transform(X_test)\n",
        "\n",
        "# Tren en ny LR på skalerte data for ren koeffisient-tolking\n",
        "linreg_scaled = LinearRegression()\n",
        "linreg_scaled.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Hent koeffisienter og tegn viktighet som |coef|\n",
        "coef = linreg_scaled.coef_\n",
        "feat_names = list(X.columns)\n",
        "imp_lr = pd.DataFrame({\n",
        "    'feature': feat_names,\n",
        "    'importance': np.abs(coef)   # absoluttverdi for rangering\n",
        "}).sort_values('importance', ascending=False).head(15)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(data=imp_lr, x='importance', y='feature')\n",
        "plt.title('Viktigste variabler (LinearRegression, standardiserte koeffisienter)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# --- Visualisering og feature-viktighet ---\n",
        "\n",
        "# Predikert vs. faktisk for XGBoost\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(y_test, y_pred_xgb, alpha=0.5)\n",
        "lims = [min(y_test.min(), y_pred_xgb.min()), max(y_test.max(), y_pred_xgb.max())]\n",
        "plt.plot(lims, lims, 'r--')\n",
        "plt.xlabel('Faktisk antall salg')\n",
        "plt.ylabel('Predikert antall salg')\n",
        "plt.title(f'Faktisk vs. predikert, produkt {TOP_PRODUCT} (XGB)')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Topp 15 features fra XGB\n",
        "imp = pd.DataFrame({'feature': feature_cols, 'importance': xgb.feature_importances_}) \\\n",
        "       .sort_values('importance', ascending=False).head(15)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(data=imp, x='importance', y='feature')\n",
        "plt.title('Viktigste variabler (XGB)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KtQ3MdYwH03H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Hold igjen siste 2 måneder som testsett ---\n",
        "\n",
        "# Forsikre at Date er datetime\n",
        "daily_prod_sales['Date'] = pd.to_datetime(daily_prod_sales['Date'])\n",
        "\n",
        "# Finn dato to måneder før slutt\n",
        "cutoff = daily_prod_sales['Date'].max() - pd.DateOffset(days=60)\n",
        "\n",
        "# Splitt data\n",
        "train_df = daily_prod_sales[daily_prod_sales['Date'] <= cutoff].copy()\n",
        "test_df  = daily_prod_sales[daily_prod_sales['Date'] > cutoff].copy()\n",
        "\n",
        "print(f\"Treningslengde: {len(train_df)} dager, Testlengde: {len(test_df)} dager\")\n",
        "\n",
        "# Lag features for begge sett\n",
        "train_df_processed, X_train2, y_train2, _ = make_prod_features(train_df)\n",
        "test_df_processed, X_test2, y_test2, _ = make_prod_features(test_df)\n",
        "\n",
        "\n",
        "# Tren modell (XGBoost) på treningsdata\n",
        "xgb2 = XGBRegressor(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=4,\n",
        "    random_state=42,\n",
        "    eval_metric='rmse',\n",
        "    early_stopping_rounds=30\n",
        ")\n",
        "xgb2.fit(X_train2, y_train2, eval_set=[(X_test2, y_test2)], verbose=False)\n",
        "\n",
        "y_pred2 = xgb2.predict(X_test2)"
      ],
      "metadata": {
        "id": "iUmyqF3hwzdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Tren lineær regresjon på samme train-features\n",
        "linreg2 = LinearRegression()\n",
        "linreg2.fit(X_train2, y_train2)\n",
        "\n",
        "# Prediksjoner\n",
        "y_pred2_lin = linreg2.predict(X_test2)\n",
        "\n",
        "# Evaluer\n",
        "print(\"Resultater for testperiode (samme hold-out):\")\n",
        "report(y_test2, y_pred2,     \"XGBRegressor hold-out\")\n",
        "report(y_test2, y_pred2_lin, \"LinearRegression hold-out\")"
      ],
      "metadata": {
        "id": "GApLgW_V0NkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bygg en daglig oversikt for testperioden med faktisk og predikert\n",
        "results_daily = test_df_processed[['Date', 'SalesCount']].copy()\n",
        "results_daily = results_daily.reset_index(drop=True)\n",
        "results_daily['Pred_XGB'] = y_pred2\n",
        "results_daily['Pred_LR']  = y_pred2_lin\n",
        "\n",
        "# Valgfritt: rund av for penere visning\n",
        "results_daily['SalesCount'] = results_daily['SalesCount'].round(2)\n",
        "results_daily['Pred_XGB']   = results_daily['Pred_XGB'].round(2)\n",
        "results_daily['Pred_LR']    = results_daily['Pred_LR'].round(2)\n",
        "\n",
        "results_daily.head(10)\n"
      ],
      "metadata": {
        "id": "wv_ywbkt5whL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(train_df_processed['Date'], train_df_processed['SalesCount'], label='Trening (historisk)')\n",
        "plt.plot(test_df_processed['Date'], test_df_processed['SalesCount'], label='Faktisk (hold-out)')\n",
        "plt.plot(test_df_processed['Date'], y_pred2, 'r--', label='Predikert XGB')\n",
        "plt.plot(test_df_processed['Date'], y_pred2_lin, 'g--', label='Predikert LR')\n",
        "plt.xlabel('Dato'); plt.ylabel('Antall salg')\n",
        "plt.title('Faktisk vs predikert salg i hold-out-perioden')\n",
        "plt.legend(); plt.grid(True); plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Zt7cSYiH58Fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hvordan kan vi forbedre modellene?\n",
        "\n",
        "Nå har vi laget to modeller (Linear Regression og XGBoost) og testet dem på en hold-out-periode. Vi så at begge modellene har et forbedringspotensial, både på nøyaktighet (lavere MAE/RMSE) og forklaringskraft (høyere R²).\n",
        "\n",
        "Her er noen forslag til hvordan dere kan eksperimentere for å forbedre modellene:\n",
        "\n",
        "### 1. Forbedre features (variabler)\n",
        "- **Flere lags**: Vi brukte lag_1 og lag_7. Hva med `lag_2`, `lag_14`, `lag_30`?  \n",
        "- **Rullerende vinduer**: Vi tok med rolling mean (7 dager). Prøv rolling mean/std på 14 eller 30 dager.  \n",
        "- **Ukedag/helg**: Bruk one-hot encoding av ukedager (Mandag–Søndag). Kanskje salget har mønstre gjennom uka.  \n",
        "- **Sesongmønstre**: Prøv å legge til måned, kvartal eller “er det månedsslutt/start?”. Andre ting som helligdager?\n",
        "\n",
        "### 2. Justere modeller og hyperparametere\n",
        "- **Linear Regression**: Prøv Ridge eller Lasso (regularisering) for å se om det forbedrer generalisering.  \n",
        "- **XGBoost**: Test ulike `max_depth`, `learning_rate`, `n_estimators` og `subsample`. Bruk grid search eller manual tuning.\n",
        "\n",
        "### 3. Endre trenings- og testoppsett\n",
        "- **Lengre hold-out**: Test om modellen klarer å predikere 3 eller 6 måneder frem i tid.  \n",
        "- **Rolling forecast**: Prøv å trene modellen frem til en dato, prediker neste dag, legg den til, og repeter. Dette speiler hvordan modeller kan brukes i praksis.  \n",
        "\n",
        "### 4. Kombinere modeller\n",
        "- Prøv å ta gjennomsnitt av Linear Regression og XGBoost sine prediksjoner. Kombinasjoner kan gi mer robuste resultater.  \n",
        "\n",
        "### 5. Diskusjonsspørsmål\n",
        "- Hvilke features tror dere har mest effekt på salget?  \n",
        "- Hva er viktigst i en praktisk sammenheng: lav MAE (gjennomsnittlig feil), lav RMSE (unngå store feil), eller høy R² (forklaringskraft)?  \n",
        "- Hvis dere skulle implementere modellen hos en bedrift, hvilke andre datakilder ville dere koblet på (vær, kampanjer, helligdager, etc.)?  \n",
        "\n",
        "---  \n",
        "Velg en av forslagene, implementer og se hvordan modellene endrer seg. Fortsett så lenge vi har tid.\n",
        "\n",
        "Diskuter om:  \n",
        "- Ble resultatene bedre?  \n",
        "- Hvilke features eller justeringer ga mest mening?  \n",
        "- Hva ville dere testet videre hvis dere hadde mer tid?\n"
      ],
      "metadata": {
        "id": "QjEeIkx48zsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Lag en pipeline med skalering + regresjon\n",
        "linreg_scaled = make_pipeline(StandardScaler(), LinearRegression())\n",
        "linreg_scaled.fit(X_train2, y_train2)\n",
        "y_pred_scaled = linreg_scaled.predict(X_test2)\n",
        "\n",
        "report(y_test2, y_pred_scaled, \"LinearRegression med skalering\")"
      ],
      "metadata": {
        "id": "diMU0uss9lmf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wakristensen/machine-learning-workshop/blob/main/04_supervised_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6P7lEmlwVbn2"
      },
      "outputs": [],
      "source": [
        "# 1) Importer biblioteker\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(\"TensorFlow:\", tf.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Produktfokusert datasett for antall salg ---\n",
        "file_id = \"1Ku-y5BE5CdGQwzEMQ491cfIYWILS6T8U\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "df = pd.read_csv(url, encoding=\"latin1\")\n",
        "# Sikre riktig dtype\n",
        "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
        "\n",
        "# Fjerner kansellerte og negative linjer, slik at \"antall salg\" kun betyr positive salg\n",
        "# Kansellerte transaksjoner har InvoiceNo som starter med 'C', negativ Quantity, og samme UnitPrice som originalen\n",
        "df_prod = df.copy()\n",
        "\n",
        "# Finne kansellerte transaksjoner\n",
        "cancelled_transactions = df_prod[df_prod['InvoiceNo'].astype(str).str.startswith('C')].copy()\n",
        "\n",
        "# Lager en unik nøkkel for å matche kansellerte transaksjoner med originale counterparts\n",
        "cancelled_transactions['match_key'] = cancelled_transactions['StockCode'].astype(str) + '_' + \\\n",
        "                                      cancelled_transactions['CustomerID'].astype(str) + '_' + \\\n",
        "                                      (cancelled_transactions['Quantity'] * -1).astype(str) + '_' + \\\n",
        "                                      cancelled_transactions['UnitPrice'].astype(str)\n",
        "\n",
        "# Finner originale transaksjoner som matcher de kansellerte\n",
        "df_prod['match_key'] = df_prod['StockCode'].astype(str) + '_' + \\\n",
        "                       df_prod['CustomerID'].astype(str) + '_' + \\\n",
        "                       df_prod['Quantity'].astype(str) + '_' + \\\n",
        "                       df_prod['UnitPrice'].astype(str)\n",
        "\n",
        "# Finner transaksjoner vi skal fjerne (kansellerte transaksjoner og deres positive counterparts)\n",
        "keys_to_remove = cancelled_transactions['match_key'].tolist()\n",
        "\n",
        "# Filtrerer vekk transaksjoner vi skal fjerne\n",
        "df_prod = df_prod[~df_prod['match_key'].isin(keys_to_remove)].copy()\n",
        "\n",
        "# Fjerner den midlertidig match-nøkkelen\n",
        "df_prod = df_prod.drop(columns=['match_key'])\n",
        "\n",
        "# Sikrer at utelukkende positive kvantiteter og unit priser står igje\n",
        "df_prod = df_prod[(df_prod['Quantity'] > 0) & (df_prod['UnitPrice'] > 0)]\n",
        "\n",
        "\n",
        "# Topp 10 etter frekvens av Description\n",
        "top_products = df_prod['Description'].value_counts().head(10)\n",
        "print(\"Topp 10 produkter:\", top_products)\n",
        "\n",
        "# Velg mest frekvente beskrivelse\n",
        "TOP_PRODUCT = df_prod['Description'].value_counts().reset_index().iloc[2][0]\n",
        "print(\"Produkt valgt (Description):\", TOP_PRODUCT)\n",
        "\n",
        "# Filtrer på Description, ikke StockCode\n",
        "prod_df = df_prod[df_prod['Description'] == TOP_PRODUCT].copy()\n",
        "\n",
        "# Sikre datetime og lag eksplisitt Date-kolonne\n",
        "prod_df['InvoiceDate'] = pd.to_datetime(prod_df['InvoiceDate'], errors='coerce')\n",
        "prod_df = prod_df.dropna(subset=['InvoiceDate'])\n",
        "\n",
        "# Behold dtype datetime64 ved å normalisere til midnatt (bedre for plotting og sortering)\n",
        "prod_df['Date'] = prod_df['InvoiceDate'].dt.normalize()\n",
        "\n",
        "# Gruppér per dag og summer Quantity\n",
        "daily_prod_sales = (\n",
        "    prod_df\n",
        "    .groupby('Date', as_index=False)['Quantity']\n",
        "    .sum()\n",
        "    .rename(columns={'Quantity': 'SalesCount'})\n",
        "    .sort_values('Date')\n",
        ")\n",
        "\n",
        "print(\"Form på daglig datasett:\", daily_prod_sales.shape)\n",
        "daily_prod_sales"
      ],
      "metadata": {
        "id": "AxsWr3OzLNse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KORT EDA\n",
        "plt.figure(figsize=(12,4))\n",
        "sns.lineplot(data=daily_prod_sales, x='Date', y='SalesCount')\n",
        "plt.title(f'Daglig antall salg, produkt {TOP_PRODUCT}')\n",
        "plt.xlabel('Dato'); plt.ylabel('Antall')\n",
        "plt.grid(True); plt.tight_layout(); plt.show()\n",
        "\n",
        "# Glidende snitt\n",
        "daily_prod_sales['Rolling7'] = daily_prod_sales['SalesCount'].rolling(7).mean()\n",
        "plt.figure(figsize=(12,4))\n",
        "sns.lineplot(data=daily_prod_sales, x='Date', y='SalesCount', label='Faktisk')\n",
        "sns.lineplot(data=daily_prod_sales, x='Date', y='Rolling7', label='Rolling7')\n",
        "plt.title('Daglig salg med 7-dagers rullende snitt')\n",
        "plt.xlabel('Dato'); plt.ylabel('Antall')\n",
        "plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()\n"
      ],
      "metadata": {
        "id": "-SisrpzYLU2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prod_features(df):\n",
        "    df = df.copy()\n",
        "    df['year'] = df['Date'].dt.year\n",
        "    df['month'] = df['Date'].dt.month\n",
        "    df['dayofweek'] = df['Date'].dt.dayofweek  # 0 mandag\n",
        "\n",
        "    # Enkle lag og rolling\n",
        "    df['lag_1'] = df['SalesCount'].shift(1)\n",
        "    df['lag_7'] = df['SalesCount'].shift(7)\n",
        "    df['roll_mean_7'] = df['SalesCount'].rolling(7).mean()\n",
        "\n",
        "    # Dropp NaN som følger av lag og rolling\n",
        "    df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "    feature_cols = ['year', 'month', 'dayofweek', 'lag_1', 'lag_7', 'roll_mean_7']\n",
        "    X = df[feature_cols]\n",
        "    y = df['SalesCount']\n",
        "    return df, X, y, feature_cols\n",
        "\n",
        "features_df, X, y, feature_cols = make_prod_features(daily_prod_sales)\n",
        "features_df.head()\n"
      ],
      "metadata": {
        "id": "5uqJQG1ULXvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Del etter dato, ikke shuffle\n",
        "cutoff = features_df['Date'].max() - pd.DateOffset(days=45)\n",
        "train_mask = features_df['Date'] <= cutoff\n",
        "test_mask  = features_df['Date'] >  cutoff\n",
        "\n",
        "X_train, y_train = X[train_mask], y[train_mask]\n",
        "X_test,  y_test  = X[test_mask],  y[test_mask]\n",
        "\n",
        "# Skaler features (NN liker skalerte data)\n",
        "scaler = StandardScaler()\n",
        "X_train_sc = scaler.fit_transform(X_train)\n",
        "X_test_sc  = scaler.transform(X_test)\n",
        "\n",
        "X_train.shape, X_test.shape\n"
      ],
      "metadata": {
        "id": "ZNipe2mRMEo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Enkel MLP\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(X_train_sc.shape[1],)), #Definerer input formen (antall features i X)\n",
        "    layers.Dense(64, activation='relu'), # Et fullkoblet lag med 64 noder, ReLU som aktiveringsfunksjon\n",
        "    layers.Dense(32, activation='relu'), # Nytt lag med 32 noder\n",
        "    layers.Dense(1)  # regresjon - outputlaget med 1 node, siden vi predikerer en kontinuerlig verdi (Antall salg), ingen aktivering herm siden det er regresjon\n",
        "])\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3), # Hvordan modellen skal lære (backpropagation) Adam er en populær gradient descent-algoritme\n",
        "              loss='mse', # Kostnadsfunksjonen, mean squared error, vanlig for regresjon\n",
        "              metrics=[keras.metrics.RootMeanSquaredError(name='rmse')])  # Overvåker RMSE under trening og validering\n",
        "\n",
        "callbacks = [ #Callbacks er små hjelpere som styrer trening underveis\n",
        "    # Stopper treningen hvis validerings-RMSE ikke blir bedre på 10 epoker. Restore_best_weights gjør at modellen går tilbake til vektene som ga best resultat\n",
        "    keras.callbacks.EarlyStopping(monitor='val_rmse', patience=10, restore_best_weights=True),\n",
        "    # ReduceLROnPlateu halverer læringsraten hvis validerings-RMSE ikke forbedres på 5 epoker. Det hjelper modellen med \"finpussing\" når forbedringen flater ut\n",
        "    keras.callbacks.ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=5, verbose=0)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_sc, y_train, # Treningsdata\n",
        "    validation_data=(X_test_sc, y_test), # Brukes til å måle ytelse underveis\n",
        "    epochs=200, # Maks antall gjennomganger av treningssettet, kan stoppe tidligere pga earlystopping\n",
        "    batch_size=50, # Antall observasjoner i hver batch, delmengde av data som oppdaterer vektene\n",
        "    callbacks=callbacks, # Kobler inn earlystopping og reduce on plateau\n",
        "    verbose=0 # Undertrykker logging i output\n",
        ")\n",
        "\n",
        "print(\"Beste val-RMSE:\", np.min(history.history['val_rmse']))\n"
      ],
      "metadata": {
        "id": "EN9xj86dMIbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksjoner\n",
        "y_pred_nn = model.predict(X_test_sc).ravel()\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred_nn)\n",
        "rmse_val = rmse(y_test, y_pred_nn)\n",
        "r2 = r2_score(y_test, y_pred_nn)\n",
        "\n",
        "print(f\"NN -> MAE: {mae:.2f} | RMSE: {rmse_val:.2f} | R²: {r2:.3f}\")\n",
        "\n",
        "# Plot faktisk vs predikert på dato\n",
        "test_dates = features_df.loc[test_mask, 'Date'].reset_index(drop=True)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.plot(test_dates, y_test.values, label='Faktisk')\n",
        "plt.plot(test_dates, y_pred_nn, 'r--', label='Predikert (NN)')\n",
        "plt.title('Faktisk vs predikert i hold‑out perioden')\n",
        "plt.xlabel('Dato'); plt.ylabel('Antall salg')\n",
        "plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()\n",
        "\n",
        "# Scatter: faktisk vs predikert\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(y_test, y_pred_nn, alpha=0.6)\n",
        "lims = [min(y_test.min(), y_pred_nn.min()), max(y_test.max(), y_pred_nn.max())]\n",
        "plt.plot(lims, lims, 'r--')\n",
        "plt.xlabel('Faktisk'); plt.ylabel('Predikert')\n",
        "plt.title('Faktisk vs predikert (NN)')\n",
        "plt.grid(True); plt.tight_layout(); plt.show()\n"
      ],
      "metadata": {
        "id": "hsxERZfDMMGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Liten baseline-sjekk for sammenligning\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "linreg = LinearRegression()\n",
        "linreg.fit(X_train_sc, y_train)\n",
        "y_pred_lin = linreg.predict(X_test_sc)\n",
        "\n",
        "mae_lr  = mean_absolute_error(y_test, y_pred_lin)\n",
        "rmse_lr = rmse(y_test, y_pred_lin)\n",
        "r2_lr   = r2_score(y_test, y_pred_lin)\n",
        "\n",
        "print(f\"LR  -> MAE: {mae_lr:.2f} | RMSE: {rmse_lr:.2f} | R²: {r2_lr:.3f}\")\n",
        "print(f\"NN  -> MAE: {mae:.2f} | RMSE: {rmse_val:.2f} | R²: {r2:.3f}\")\n"
      ],
      "metadata": {
        "id": "TqRp6dE1MRBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ble NN bedre enn baseline?\n",
        "1) Sammenlign MAE, RMSE og R² for NN og Linear Regression.\n",
        "2) Prøv å forbedre NN litt:\n",
        "   - Øk antall noder i første lag (for eksempel 128).\n",
        "   - Legg til Dropout(0.2) mellom lagene.\n",
        "   - Endre læringsraten i Adam fra 1e-3 til 5e-4.\n",
        "   - Kjør noen få runder til og se om validerings-RMSE går ned.\n",
        "\n",
        "Refleksjon:\n",
        "- Hva skjer med valideringskurven når du øker modellen?\n",
        "- Overtrener modellen raskere?\n",
        "- Hva ville du gjort for å stabilisere treningen (flere data, enklere features, annen hold‑out)?\n"
      ],
      "metadata": {
        "id": "g6YdVYtsMXHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bonus: litt større modell\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "big_model = keras.Sequential([\n",
        "    layers.Input(shape=(X_train_sc.shape[1],)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "])\n",
        "\n",
        "big_model.compile(optimizer=keras.optimizers.Adam(learning_rate=5e-4),\n",
        "                  loss='mse',\n",
        "                  metrics=[keras.metrics.RootMeanSquaredError(name='rmse')])\n",
        "\n",
        "history2 = big_model.fit(\n",
        "    X_train_sc, y_train,\n",
        "    validation_data=(X_test_sc, y_test),\n",
        "    epochs=250,\n",
        "    batch_size=32,\n",
        "    callbacks=[\n",
        "        keras.callbacks.EarlyStopping(monitor='val_rmse', patience=12, restore_best_weights=True),\n",
        "        keras.callbacks.ReduceLROnPlateau(monitor='val_rmse', factor=0.5, patience=6, verbose=0)\n",
        "    ],\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "y_pred_big = big_model.predict(X_test_sc).ravel()\n",
        "print(\"Bonus NN -> MAE:\", mean_absolute_error(y_test, y_pred_big),\n",
        "      \"| RMSE:\", rmse(y_test, y_pred_big),\n",
        "      \"| R²:\", r2_score(y_test, y_pred_big))\n"
      ],
      "metadata": {
        "id": "GchWGL8mMWie"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}